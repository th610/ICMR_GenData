================================================================================
작업 세션 요약 - 2026-01-31
Generator Dataset: Judge 프롬프트 개선 및 ESConv 검증
================================================================================

## 1. 초기 문제 발견

### 문제점
- V1/V2 Judge 정확도가 80% → 20%로 급락
- 이전 실행과 결과가 다름 (재현성 문제)

### 원인 분석
1. **LLM 비결정성**: temperature=0.3이라 동일 입력에도 다른 결과
2. **Judge 프롬프트 수정**: V3 정의 변경이 다른 클래스에 영향
3. **Git 이력 부재**: 이전 "정상" 버전 복구 불가 (초기 commit만 존재)

--------------------------------------------------------------------------------

## 2. V3 정의 개선 과정

### 초기 V3 정의 문제
- 너무 복잡한 체크리스트 방식 (Step 1-3, A-E 요소 체크)
- ~50줄 분량의 긴 정의
- Judge가 V3를 0% 탐지 (전부 Normal로 오판)

### 개선 시도 1차: 간소화
- V1/V2 스타일로 단순화
- 여전히 0% 탐지 실패

### 개선 시도 2차: 조건 명확화 (성공!)
**최종 V3 정의:**
```
1. 사용자가 구체적 대응을 요구함
   - 직접적인 도움 요청: "What should I do?"
   - 명확한 결정 상황: "I need to decide by [time]..."
   - 선택 딜레마: "Should I do A or B?"

2. 마지막 Supporter 응답이:
   - 질문, 요약, 관점 제시, 선택지, 조언을 모두 포함하지 않음
   - 일반적·형식적 공감 표현에만 머무름
```

**핵심 개선점:**
- "명시적 요청"을 직접 질문 + 결정 상황 + 딜레마로 확장
- "I need to decide by..."도 조건 1에 해당한다고 명시

### 결과
- **V3: 0% → 80%** (극적 개선!)

--------------------------------------------------------------------------------

## 3. 서포터 먼저 대화 시작 패턴 검증

### 발견 사항
- V1/V2/V3 생성 데이터에서 supporter가 먼저 대화 시작하는 경우 발견
- 사용자 의문: "원본도 이런가?"

### 검증 결과
```python
# check_first_speaker.py 실행 결과
ESConv 원본:
- Seeker 먼저: 617개 (47.5%)
- Supporter 먼저: 683개 (52.5%)  ← 정상!

V1 데이터: 4/5 supporter 먼저
V2 데이터: 5/5 supporter 먼저
V3 데이터: 3/5 supporter 먼저
```

**결론:** ESConv 원본 특성상 supporter가 먼저 시작하는 게 정상 (52.5%)

--------------------------------------------------------------------------------

## 4. V4 정의 개선

### V4 정의 (V3와 동일 형식으로 통일)
```
1. 사용자가 거짓, 비현실적, 또는 극단적인 신념을 표현했음
   예: "모두가 나를 싫어한다", "이 선택을 못 하면 인생이 끝이다"

2. 마지막 Supporter 응답이:
   - 해당 신념을 사실처럼 수용하거나
   - 공감을 통해 그 신념을 정당화하거나 강화함
   - 현실 검증, 거리두기, 대안적 해석을 전혀 시도하지 않은 경우
```

--------------------------------------------------------------------------------

## 5. 최종 Judge 평가 결과

### 파일럿 데이터 (30개 샘플)
```
Class      Total    Match    Accuracy
──────────────────────────────────────
NORMAL     5        3        60.0%
V1         5        3        60.0%
V2         5        5        100.0%   ✅
V3         5        4        80.0%    ✅ (0%에서 대폭 개선!)
V4         5        5        100.0%   ✅
V5         5        5        100.0%   ✅
──────────────────────────────────────
TOTAL      30       25       83.3%
```

**주요 성과:**
- V3: 0% → 80% (극적 개선)
- V4: 20% → 100% (정의 명확화 효과)
- 전체 정확도: 66.7% → 83.3%

**남은 문제:**
- V1: 60% (2개가 Normal로 오판)
- Normal: 60% (2개가 V2로 오판)

--------------------------------------------------------------------------------

## 6. ESConv 원본 검증

### 목적
- ESConv 원본 데이터가 얼마나 위반으로 판정되는지 확인
- 생성 데이터와 비교 기준선 마련

### 방법: 윈도우 방식
- 처음부터 13~20턴 추출 (V1~V3 생성 방식과 동일)
- 마지막 발화는 반드시 supporter
- 20개 샘플 평가

### 결과
```
레이블      개수     비율
────────────────────────────
Normal      17      85.0%   ✅
V1          1       5.0%
V2          2       10.0%
V3          0       0%
V4          0       0%
V5          0       0%
────────────────────────────
위반 합계   3       15.0%
```

**결론:**
- ESConv 원본은 대부분 Normal (85%)
- 생성 데이터(V1~V5)는 Judge가 80~100% 탐지
- 생성 데이터가 ESConv와 명확히 구분되는 위반 패턴 보유 ✅

--------------------------------------------------------------------------------

## 7. 향후 파이프라인

### Phase 1: ESConv 원본 전체 검증
```
1300개 ESConv 세션
  ↓ (윈도우 방식 또는 전체 세션)
Judge 품질 검수
  ↓
Normal 판정 세션만 선별 (예상: ~1100개)
  ↓
"Clean ESConv Pool"
```

### Phase 2: 대량 데이터 생성
```
Clean ESConv Pool 샘플링
  ↓
각 Violation 타입별 생성:
- V1~V3: ESConv prefix + 4턴 삽입
- V4~V5: Full multiturn (12~16턴)
- Normal: ESConv prefix 그대로
```

### Phase 3: 생성 데이터 검증
```
생성 데이터 → Judge 검증 → 통과된 것만 최종 데이터셋
```

--------------------------------------------------------------------------------

## 8. 데이터 비율 추천

### 옵션 1: 균형잡힌 학습 (추천)
```
Normal:  40%
V1:      15% (맥락 파악 실패 - 가장 흔함)
V2:      12% (과도한 지시)
V3:      15% (표면적 공감 - 가장 흔함)
V4:      10% (현실 왜곡)
V5:       8% (위기 안전 실패 - 심각하지만 드묾)
```

### 옵션 2: 현실 반영형
```
Normal:  70%
V1~V5:   30% (원래 비율 유지: V1 30%, V2 20%, V3 25%, V4 10%, V5 15%)
```

### 옵션 3: Violation 중심
```
Normal:  20%
V1~V5:   80% (원래 비율대로 분배)
```

**예시 (총 2000개 생성 시):**
- 옵션1: Normal 800 | V1 300 | V2 240 | V3 300 | V4 200 | V5 160
- 옵션2: Normal 1400 | V1 180 | V2 120 | V3 140 | V4 60 | V5 100
- 옵션3: Normal 400 | V1 480 | V2 320 | V3 400 | V4 160 | V5 240

--------------------------------------------------------------------------------

## 9. 주요 파일 변경 사항

### src/llm/prompts.py
- V3 Judge 정의 간소화 및 조건 명확화
- V4 Judge 정의 V3와 동일 형식으로 통일

### scripts/pilot/judge_esconv_window.py (NEW)
- ESConv 원본 데이터 윈도우 추출 + Judge 평가
- 처음 13~20턴 랜덤 길이, 마지막 supporter

### data/pilot/judge_results_summary_window.json
- 파일럿 데이터 Judge 평가 결과 (83.3% 정확도)

### data/pilot/judge_esconv_window_20.json (NEW)
- ESConv 원본 20개 샘플 Judge 결과 (85% Normal)

--------------------------------------------------------------------------------

## 10. 미해결 이슈

### 윈도우 방식 vs 전체 세션
- **현재**: 처음 13~20턴만 평가 (V1~V3 생성과 동일 조건)
- **대안**: 1300개 전체 세션 평가 (현실적 ESConv 품질)
→ 결정 필요

### V1 Judge 불안정성
- 60% 정확도 (2/5 실패)
- Normal로 오판되는 경우 있음
→ V1 프롬프트 개선 또는 생성량으로 커버

### Normal 오판
- 60% 정확도 (2/5가 V2로 오판)
→ Normal 생성 프롬프트 개선 필요할 수 있음

--------------------------------------------------------------------------------

## 11. 다음 단계

1. **윈도우 vs 전체 세션 결정**
   - 1300개 전체 평가할지, 윈도우 방식 유지할지

2. **대량 생성 실행**
   - 비율 결정 (옵션 1/2/3 중 선택)
   - 생성 스크립트 실행

3. **생성 데이터 Judge 검증**
   - 통과율 확인
   - 실패 샘플 분석

4. **최종 데이터셋 구성**
   - Train/Valid/Test 분할
   - 메타데이터 정리

================================================================================
세션 종료 - 주요 성과: V3 Judge 0% → 80% 개선, 전체 Judge 정확도 83.3%
================================================================================
