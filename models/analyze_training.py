"""
í•™ìŠµëœ ëª¨ë¸ ë¶„ì„
- Epochë³„ ì„±ëŠ¥ ì¶”ì´
- í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
- ëª¨ë¸ ì •ë³´
"""
import json
import re
from pathlib import Path

# ë¡œê·¸ íŒŒì¼ ì½ê¸°
log_file = Path("models/training.log")
with open(log_file, 'r') as f:
    log_content = f.read()

# Epochë³„ ì„±ëŠ¥ ì¶”ì¶œ
epoch_pattern = r"Epoch (\d+)/10"
valid_metrics_pattern = r"Loss: ([\d.]+)\nAccuracy: ([\d.]+)\nMacro Precision: ([\d.]+)\nMacro Recall: ([\d.]+)\nMacro F1: ([\d.]+)"

epochs = re.findall(epoch_pattern, log_content)
sections = re.split(epoch_pattern, log_content)

print("="*80)
print("í•™ìŠµ ì„±ëŠ¥ ì¶”ì´ (Epochë³„)")
print("="*80)
print(f"{'Epoch':<8} {'Loss':<10} {'Accuracy':<12} {'Macro P':<12} {'Macro R':<12} {'Macro F1':<12}")
print("-"*80)

epoch_data = []
for i in range(1, len(sections), 2):
    epoch_num = sections[i]
    epoch_content = sections[i+1]
    
    # Valid ì„±ëŠ¥ ì°¾ê¸°
    valid_match = re.search(valid_metrics_pattern, epoch_content)
    if valid_match:
        loss, acc, prec, rec, f1 = valid_match.groups()
        epoch_data.append({
            'epoch': int(epoch_num),
            'loss': float(loss),
            'accuracy': float(acc),
            'precision': float(prec),
            'recall': float(rec),
            'f1': float(f1)
        })
        print(f"{epoch_num:<8} {loss:<10} {acc:<12} {prec:<12} {rec:<12} {f1:<12}")

# ì„±ëŠ¥ ê°œì„  ë¶„ì„
print("\n" + "="*80)
print("ì„±ëŠ¥ ê°œì„  ë¶„ì„")
print("="*80)

if len(epoch_data) > 1:
    print(f"\nEpoch 1 â†’ Epoch {len(epoch_data)}:")
    print(f"  Accuracy: {epoch_data[0]['accuracy']:.4f} â†’ {epoch_data[-1]['accuracy']:.4f} (+{epoch_data[-1]['accuracy'] - epoch_data[0]['accuracy']:.4f})")
    print(f"  Macro F1: {epoch_data[0]['f1']:.4f} â†’ {epoch_data[-1]['f1']:.4f} (+{epoch_data[-1]['f1'] - epoch_data[0]['f1']:.4f})")
    print(f"  Loss:     {epoch_data[0]['loss']:.4f} â†’ {epoch_data[-1]['loss']:.4f} ({epoch_data[-1]['loss'] - epoch_data[0]['loss']:.4f})")

# Best epoch ì°¾ê¸°
best_epoch = max(epoch_data, key=lambda x: x['f1'])
print(f"\nBest Epoch: {best_epoch['epoch']}")
print(f"  Macro F1: {best_epoch['f1']:.4f}")
print(f"  Accuracy: {best_epoch['accuracy']:.4f}")

# Test metrics ì½ê¸°
print("\n" + "="*80)
print("ìµœì¢… Test Gold ì„±ëŠ¥")
print("="*80)

metrics_file = Path("models/outputs/test_metrics.json")
if metrics_file.exists():
    with open(metrics_file, 'r') as f:
        metrics = json.load(f)
    
    print(f"\nBest Epoch: {metrics['best_epoch']}")
    print(f"Best Metric (Macro F1): {metrics['best_metric']:.4f}")
    print(f"\nFinal Test Results:")
    print(f"  Accuracy:       {metrics['final_metrics']['accuracy']:.4f}")
    print(f"  Macro F1:       {metrics['final_metrics']['macro_f1']:.4f}")
    print(f"  Macro Precision: {metrics['final_metrics']['macro_precision']:.4f}")
    print(f"  Macro Recall:    {metrics['final_metrics']['macro_recall']:.4f}")
    print(f"  V5 Recall:       {metrics['final_metrics']['v5_recall']:.4f} ğŸ¯")
    
    print(f"\nPer-Class F1:")
    labels = ['Normal', 'V1', 'V2', 'V3', 'V4', 'V5']
    for label, f1 in zip(labels, metrics['final_metrics']['per_class_f1']):
        print(f"  {label:<8}: {f1:.4f}")
    
    print(f"\nConfusion Matrix:")
    print(f"{'Trueâ†“/Predâ†’':<12} {'Normal':<8} {'V1':<8} {'V2':<8} {'V3':<8} {'V4':<8} {'V5':<8}")
    print("-"*80)
    cm = metrics['final_metrics']['confusion_matrix']
    for i, row in enumerate(cm):
        print(f"{labels[i]:<12} {row[0]:<8} {row[1]:<8} {row[2]:<8} {row[3]:<8} {row[4]:<8} {row[5]:<8}")

# ëª¨ë¸ ì •ë³´
print("\n" + "="*80)
print("ëª¨ë¸ ì •ë³´")
print("="*80)

model_file = Path("models/outputs/best_model.pt")
if model_file.exists():
    size_mb = model_file.stat().st_size / (1024 * 1024)
    print(f"\nModel File: {model_file}")
    print(f"Size: {size_mb:.1f} MB")
    
    import torch
    checkpoint = torch.load(model_file, map_location='cpu')
    print(f"\nCheckpoint Info:")
    print(f"  Epoch: {checkpoint['epoch']}")
    print(f"  Best Metric: {checkpoint['best_metric']:.4f}")
    if 'train_config' in checkpoint:
        cfg = checkpoint['train_config']
        print(f"\nTrain Config:")
        for key, val in cfg.items():
            print(f"  {key}: {val}")

# Early stopping ë¶„ì„
print("\n" + "="*80)
print("Early Stopping ë¶„ì„")
print("="*80)

if "Early stopping triggered" in log_content:
    match = re.search(r"Early stopping triggered at epoch (\d+)", log_content)
    if match:
        stopped_epoch = match.group(1)
        print(f"\nâœ… Early stopping ì‘ë™: Epoch {stopped_epoch}")
        print(f"Patience: 3 (ì„¤ì •ê°’)")
        print(f"Best epochì´ {best_epoch['epoch']}ì´ë¯€ë¡œ, {int(stopped_epoch) - best_epoch['epoch']}ë²ˆ ì—°ì† ê°œì„  ì—†ì—ˆìŒ")

# ì˜¤ë²„í”¼íŒ… ë¶„ì„
print("\n" + "="*80)
print("ì˜¤ë²„í”¼íŒ… ë¶„ì„")
print("="*80)

if epoch_data[-1]['accuracy'] == 1.0:
    print("\nâš ï¸  ì£¼ì˜: Valid Accuracy 100%")
    print("ê°€ëŠ¥í•œ ì›ì¸:")
    print("  1. ë°ì´í„°ê°€ ë§¤ìš° ëª…í™•í•˜ê²Œ êµ¬ë¶„ë¨ (ì¢‹ì€ ê²½ìš°)")
    print("  2. Overfitting (ë¬¸ì œ ê°€ëŠ¥ì„±)")
    print("  3. ë°ì´í„° ëˆ„ìˆ˜ (ê°€ëŠ¥ì„± ë‚®ìŒ)")
    print("\nê¶Œì¥ ì¡°ì¹˜:")
    print("  - ì‹¤ì œ ìƒˆë¡œìš´ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸")
    print("  - Cross-validation ìˆ˜í–‰")
    print("  - ë” ì–´ë ¤ìš´ ìƒ˜í”Œ ì¶”ê°€")
else:
    print("\nâœ… Valid Accuracy < 100%: ê±´ê°•í•œ í•™ìŠµ")

print("\n" + "="*80)
