# Dataset Generation ì‘ì—… ì •ë¦¬

**ì‘ì„±ì¼**: 2026-02-04  
**í”„ë¡œì íŠ¸**: ICMR_GenData - Empathy Violation Detection Dataset

---

## ğŸ“‹ ëª©ì°¨

1. [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)
2. [ì‘ì—… íˆìŠ¤í† ë¦¬](#ì‘ì—…-íˆìŠ¤í† ë¦¬)
3. [í˜„ì¬ ìƒíƒœ](#í˜„ì¬-ìƒíƒœ)
4. [ë‹¤ìŒ ë‹¨ê³„](#ë‹¤ìŒ-ë‹¨ê³„)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

### ëª©í‘œ
ESConv ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ **ê³µê° ìœ„ë°˜ íƒì§€ë¥¼ ìœ„í•œ 1300ê°œì˜ í•©ì„± ëŒ€í™” ìƒ˜í”Œ ìƒì„±**

### ë°ì´í„° ë¶„í¬
- **Normal**: 525ê°œ (40.4%) - ìœ„ë°˜ ì—†ìŒ
- **V1 (Context)**: 200ê°œ (15.4%) - ë§¥ë½ ë¬´ì‹œ
- **V2 (Autonomy)**: 200ê°œ (15.4%) - ììœ¨ì„± ì¹¨í•´  
- **V3 (Empathy-only)**: 200ê°œ (15.4%) - ê³µê°ë§Œ ìˆê³  ì¡°ì–¸ ì—†ìŒ
- **V4 (Reality)**: 100ê°œ (7.7%) - í˜„ì‹¤ ì™œê³¡
- **V5 (Crisis)**: 75ê°œ (5.8%) - ìœ„ê¸° ìƒí™© ì‹¤íŒ¨

**ì´**: 1300ê°œ ìƒ˜í”Œ, **1300ê°œ ìœ ë‹ˆí¬ ì„¸ì…˜** (ì¤‘ë³µ ì—†ìŒ)

### ë°ì´í„° ì†ŒìŠ¤
- `ESConv_normal_prefixes.json`: 1225ê°œ ì¼ë°˜ ì„¸ì…˜
- `ESConv_v5_prefixes.json`: 75ê°œ ìœ„ê¸° ì„¸ì…˜ (crisis trigger í¬í•¨)

---

## ğŸ“œ ì‘ì—… íˆìŠ¤í† ë¦¬

### Phase 1: í”„ë¡¬í”„íŠ¸ ê°œë°œ (ì™„ë£Œ âœ“)

**ì‘ì—… ë‚´ìš©**:
- V1-V5, Normal í”„ë¡¬í”„íŠ¸ anti-templating ê°•í™”
- ê° ìœ„ë°˜ íƒ€ì…ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‘ì„±
- Build function êµ¬í˜„ (`prompts.py`)

**ì£¼ìš” ê°œì„ ì **:
- í…œí”Œë¦¿í™” ë°©ì§€ ì§€ì¹¨ ì¶”ê°€
- Prefixì™€ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²° ê°•ì¡°
- ìœ„ë°˜ì˜ ëª…í™•ì„±ê³¼ ë¯¸ë¬˜í•¨ ê· í˜•

---

### Phase 2: Pilot Test (ì™„ë£Œ âœ“)

**ìŠ¤í¬ë¦½íŠ¸**: `pilot_test_generation.py`  
**ê²°ê³¼**: 30/30 ì„±ê³µ (100%)  
- ê° ë¼ë²¨ë‹¹ 5ê°œì”© ìƒ˜í”Œë§ (seed=42)
- ëª¨ë“  í”„ë¡¬í”„íŠ¸ ì •ìƒ ì‘ë™ í™•ì¸

**ì¶œë ¥**: `pilot_test_samples.json` (ì‚­ì œë¨)

---

### Phase 3: ì²« ë²ˆì§¸ ì „ì²´ ìƒì„± ì‹œë„ (ì‹¤íŒ¨ âŒ)

**ìŠ¤í¬ë¦½íŠ¸**: `generate_parallel.py`  
**ì „ëµ**: 1300ê°œë¥¼ 5ê°œ ë²”ìœ„ë¡œ ë¶„í•  (0-260, 260-520, ...)

**ë¬¸ì œ**:
- API Rate Limit ì´ˆê³¼ (RPM: 500)
- 6ê°œ ë³‘ë ¬ í”„ë¡œì„¸ìŠ¤ê°€ ê³¼ë¶€í•˜ ìœ ë°œ
- 641/1300ë§Œ ìƒì„± í›„ ì¤‘ë‹¨

**ê²°ê³¼**: 641ê°œ ë¶ˆì™„ì „ ìƒ˜í”Œ ìƒì„± â†’ íê¸°

---

### Phase 4: Label-based ìƒì„± (ë¶€ë¶„ ì„±ê³µ âš ï¸)

**ìŠ¤í¬ë¦½íŠ¸**: `generate_by_label.py`  
**ì „ëµ**: ë¼ë²¨ë³„ ë…ë¦½ ìƒì„±

**ì‹¤í–‰ ê²°ê³¼**:
- âœ… V1: 200/200
- âœ… V2: 200/200
- âœ… V3: 200/200
- âœ… V4: 100/100
- âš ï¸ V5: 74/75 (ì„¸ì…˜ 947 ëˆ„ë½)
- âš ï¸ Normal: 145/525 (í„°ë¯¸ë„ ì¤‘ë‹¨)

**ë¬¸ì œ ë°œê²¬**:
1. **í„°ë¯¸ë„ ê´€ë¦¬**: Agentê°€ ì‹¤í–‰ ì¤‘ì¸ í„°ë¯¸ë„ì—ì„œ ëª…ë ¹ ì‹¤í–‰í•˜ì—¬ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨
2. **Normal ì¤‘ë‹¨**: 145ê°œ ìƒì„± í›„ KeyboardInterrupt

---

### Phase 5: Normal ë³µêµ¬ ë° ì™„ë£Œ (ì™„ë£Œ âœ“)

**ì „ëµ**: Normalì„ 3ê°œë¡œ ë¶„í• í•˜ì—¬ ë³‘ë ¬ ìƒì„±

**ìŠ¤í¬ë¦½íŠ¸**:
- `run_normal_part1.py`: 0-175 (175ê°œ)
- `run_normal_part2.py`: 175-350 (175ê°œ)
- `run_normal_part3.py`: 350-525 (175ê°œ)

**ê²°ê³¼**:
- Part 1: 175/175 âœ“
- Part 2: 175/175 âœ“
- Part 3: 175/175 âœ“
- **ë³‘í•©**: 525/525 âœ“

**V5 ìˆ˜ì •**:
- `fix_v5.py`ë¡œ ì„¸ì…˜ 947 ìƒì„±
- V5: 75/75 âœ“

**ìƒì„± ì™„ë£Œ**: 1299/1300 (99.9%)

---

### Phase 6: ì¤‘ë³µ ì„¸ì…˜ ë¬¸ì œ ë°œê²¬ (ì¹˜ëª…ì  âŒ)

**ë¬¸ì œ ë¶„ì„**:
```python
# ê° ë¼ë²¨ì´ ê°™ì€ normal_prefixesì—ì„œ ë‹¤ë¥¸ seedë¡œ ìƒ˜í”Œë§
seed_map = {"V1": 1, "V2": 2, "V3": 3, "V4": 4, "Normal": 5}
random.seed(seed_map[label])
prefixes = random.sample(all_prefixes, count)
```

**ê²°ê³¼**:
- ìƒì„±ëœ ìƒ˜í”Œ: 1299ê°œ
- **ì‹¤ì œ ìœ ë‹ˆí¬ ì„¸ì…˜: 918ê°œë§Œ** âŒ
- ì¤‘ë³µ ì˜ˆì‹œ:
  - V1 & V2 overlap: 30 sessions
  - V1 & V3 overlap: 33 sessions
  - V1 & Normal overlap: 89 sessions
  - (ì´ 11ê°œ ì¡°í•©ì—ì„œ ì¤‘ë³µ ë°œìƒ)

**ì›ì¸**: ê° ë¼ë²¨ì´ ë…ë¦½ì ìœ¼ë¡œ ìƒ˜í”Œë§í–ˆì§€ë§Œ, ê°™ì€ poolì—ì„œ ë½‘ì•„ì„œ ì¤‘ë³µ ë°œìƒ

**ìš”êµ¬ì‚¬í•­ ì¬í™•ì¸**:
- "ëª¨ë“  ë‹¤ë¥¸ ì„¸ì…˜ì—ì„œ ìœ„ë°˜ ë§Œë“¤ê¸°"
- **1300ê°œ ì™„ì „íˆ ìœ ë‹ˆí¬í•œ ì„¸ì…˜ ì‚¬ìš©** í•„ìš”

---

### Phase 7: ì •ë¦¬ ë° ì¬ì„¤ê³„ (ì§„í–‰ ì¤‘ ğŸ”„)

#### 7.1 íŒŒì¼ ì •ë¦¬ (ì™„ë£Œ âœ“)

**ì‚­ì œëœ íŒŒì¼**:
- ìƒì„± ë°ì´í„°: `generated_V1~V5.json`, `generated_Normal*.json`, `generated_part*.json`
- ì„ì‹œ ìŠ¤í¬ë¦½íŠ¸: `run_normal_part*.py`, `generate_normal_part*.py`, `continue_normal.py`, `fix_v5.py`, `check_sessions.py`, `merge_normal.py`, `generate_parallel.py`

**ìœ ì§€ëœ íŒŒì¼**:
- `generate_by_label.py`: ì°¸ê³ ìš©
- `generate_full_1300.py`: ì°¸ê³ ìš©
- `create_assignments.py`: ì„¸ì…˜ í• ë‹¹ ìŠ¤í¬ë¦½íŠ¸

#### 7.2 ì„¸ì…˜ ì¬í• ë‹¹ (ì™„ë£Œ âœ“)

**ìŠ¤í¬ë¦½íŠ¸**: `create_assignments.py`

**ì „ëµ**:
```python
# 1. normal_prefixes 1225ê°œë¥¼ ì„ìŒ (seed=42)
random.seed(42)
sampled_1225 = random.sample(normal_prefixes, 1225)

# 2. ì¤‘ë³µ ì—†ì´ ë¶„í• 
splits = {
    "Normal": sampled_1225[0:525],      # 0-525
    "V1": sampled_1225[525:725],        # 525-725
    "V2": sampled_1225[725:925],        # 725-925
    "V3": sampled_1225[925:1125],       # 925-1125
    "V4": sampled_1225[1125:1225],      # 1125-1225
    "V5": v5_prefixes                   # 75ê°œ (ë³„ë„)
}
```

**ê²€ì¦ ê²°ê³¼**:
- âœ… ì´ 1300ê°œ ìƒ˜í”Œ
- âœ… 1300ê°œ ìœ ë‹ˆí¬ ì„¸ì…˜
- âœ… ë¼ë²¨ ê°„ ì¤‘ë³µ ì—†ìŒ

**ì¶œë ¥ íŒŒì¼**:
- `ESConv_v1_assigned.json` (200 sessions)
- `ESConv_v2_assigned.json` (200 sessions)
- `ESConv_v3_assigned.json` (200 sessions)
- `ESConv_v4_assigned.json` (100 sessions)
- `ESConv_normal_assigned.json` (525 sessions)
- `ESConv_v5_assigned.json` (75 sessions)
- `session_assignments.json` (í• ë‹¹ ê¸°ë¡)

#### 7.3 ìƒˆ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (ì™„ë£Œ âœ“)

**ìŠ¤í¬ë¦½íŠ¸ ëª©ë¡**:

1. **gen_v1.py**: V1 200ê°œ ìƒì„±
   - ì…ë ¥: `ESConv_v1_assigned.json`
   - ì¶œë ¥: `generated_V1.json`

2. **gen_v2.py**: V2 200ê°œ ìƒì„±
   - ì…ë ¥: `ESConv_v2_assigned.json`
   - ì¶œë ¥: `generated_V2.json`

3. **gen_v3.py**: V3 200ê°œ ìƒì„±
   - ì…ë ¥: `ESConv_v3_assigned.json`
   - ì¶œë ¥: `generated_V3.json`

4. **gen_v4.py**: V4 100ê°œ ìƒì„±
   - ì…ë ¥: `ESConv_v4_assigned.json`
   - ì¶œë ¥: `generated_V4.json`

5. **gen_normal_part1.py**: Normal 175ê°œ (0-175)
   - ì…ë ¥: `ESConv_normal_assigned.json[0:175]`
   - ì¶œë ¥: `generated_Normal_part1.json`

6. **gen_normal_part2.py**: Normal 175ê°œ (175-350)
   - ì…ë ¥: `ESConv_normal_assigned.json[175:350]`
   - ì¶œë ¥: `generated_Normal_part2.json`

7. **gen_normal_part3.py**: Normal 175ê°œ (350-525)
   - ì…ë ¥: `ESConv_normal_assigned.json[350:525]`
   - ì¶œë ¥: `generated_Normal_part3.json`

**ê³µí†µ íŠ¹ì§•**:
- OpenAI gpt-4o-mini ì‚¬ìš©
- Temperature: 0.9
- Max tokens: 800
- Timeout: 60ì´ˆ
- 20ê°œë§ˆë‹¤ progress ì¶œë ¥

---

## ğŸ“Š í˜„ì¬ ìƒíƒœ

### âœ… ì™„ë£Œëœ ì‘ì—…

1. **í”„ë¡¬í”„íŠ¸ ê°œë°œ**: V1-V5, Normal í”„ë¡¬í”„íŠ¸ ì™„ì„±
2. **ì„¸ì…˜ í• ë‹¹**: 1300ê°œ ìœ ë‹ˆí¬ ì„¸ì…˜ ì¤‘ë³µ ì—†ì´ ë¶„ë°°
3. **Assigned íŒŒì¼ ìƒì„±**: ê° ë¼ë²¨ë³„ prefix íŒŒì¼ ì¤€ë¹„
4. **ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„**: 7ê°œ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ì™„ë£Œ

### â³ ëŒ€ê¸° ì¤‘

**Phase 8: ìµœì¢… ìƒì„± ì‹¤í–‰**

#### ë³‘ë ¬ ì‹¤í–‰ ê³„íš (3ê°œì”©)

**1ì°¨ ë°°ì¹˜** (ì•½ 200ê°œì”©):
```bash
python gen_v1.py       # 200ê°œ
python gen_v2.py       # 200ê°œ
python gen_v3.py       # 200ê°œ
```

**2ì°¨ ë°°ì¹˜**:
```bash
python gen_v4.py              # 100ê°œ
python gen_normal_part1.py    # 175ê°œ
python gen_normal_part2.py    # 175ê°œ
```

**3ì°¨ ë°°ì¹˜**:
```bash
python gen_normal_part3.py    # 175ê°œ
```

#### ì˜ˆìƒ ì†Œìš” ì‹œê°„

- V1, V2, V3: ê° ~20-30ë¶„ (ë³‘ë ¬ ì‹¤í–‰)
- V4: ~10-15ë¶„
- Normal parts: ê° ~15-20ë¶„

**ì´ ì˜ˆìƒ ì‹œê°„**: ì•½ 1.5-2ì‹œê°„

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

### 1. ìµœì¢… ìƒì„± ì‹¤í–‰

**ëª…ë ¹ì–´**:
```bash
# 1ì°¨ ì‹¤í–‰ (ìƒˆ í„°ë¯¸ë„ 3ê°œ)
python gen_v1.py
python gen_v2.py  
python gen_v3.py

# 1ì°¨ ì™„ë£Œ í›„ 2ì°¨ ì‹¤í–‰
python gen_v4.py
python gen_normal_part1.py
python gen_normal_part2.py

# 2ì°¨ ì™„ë£Œ í›„ 3ì°¨ ì‹¤í–‰
python gen_normal_part3.py
```

### 2. Normal íŒŒì¼ ë³‘í•©

**ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± í•„ìš”**:
```python
# merge_final_normal.py
import json

with open("generated_Normal_part1.json") as f:
    part1 = json.load(f)
with open("generated_Normal_part2.json") as f:
    part2 = json.load(f)
with open("generated_Normal_part3.json") as f:
    part3 = json.load(f)

merged = {
    "metadata": {
        "label": "Normal",
        "target_count": 525,
        "actual_count": len(part1["samples"]) + len(part2["samples"]) + len(part3["samples"])
    },
    "samples": part1["samples"] + part2["samples"] + part3["samples"]
}

with open("generated_Normal.json", 'w', encoding='utf-8') as f:
    json.dump(merged, f, indent=2, ensure_ascii=False)
```

### 3. ìµœì¢… ê²€ì¦

**ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸**:
```python
# verify_final_dataset.py
import json

labels = ["V1", "V2", "V3", "V4", "V5", "Normal"]
all_sessions = set()

for label in labels:
    with open(f"generated_{label}.json") as f:
        data = json.load(f)
        sessions = {s["esconv_session_id"] for s in data["samples"]}
        all_sessions.update(sessions)
        print(f"{label}: {len(data['samples'])} samples, {len(sessions)} unique sessions")

print(f"\nTotal unique sessions: {len(all_sessions)}")
print(f"Target: 1300")
print(f"Status: {'âœ“ Complete' if len(all_sessions) == 1300 else 'âœ— Incomplete'}")

# Check for duplicates
total_samples = sum(len(json.load(open(f"generated_{l}.json"))["samples"]) for l in labels)
if total_samples == len(all_sessions):
    print("âœ“ No duplicate sessions across labels")
else:
    print(f"âš ï¸ Duplicates found: {total_samples - len(all_sessions)} sessions")
```

### 4. Train-Silver / Test-Gold ë¶„í• 

**ë¶„í•  ê³„íš**:
- Train-Silver: 1000 samples
- Test-Gold: 300 samples

**ë¶„í¬ ìœ ì§€**:
```python
splits = {
    "Normal": {"train": 445, "test": 80},
    "V1": {"train": 150, "test": 50},
    "V2": {"train": 140, "test": 60},
    "V3": {"train": 150, "test": 50},
    "V4": {"train": 70, "test": 30},
    "V5": {"train": 45, "test": 30}
}
```

### 5. í’ˆì§ˆ ê²€ì¦

- ê° ë¼ë²¨ë‹¹ 10-20ê°œ ìƒ˜í”Œ ì²´í¬
- í…œí”Œë¦¿í™” ì—¬ë¶€ í™•ì¸
- Prefix ì—°ì†ì„± í™•ì¸
- ìœ„ë°˜ ëª…í™•ì„± í™•ì¸

---

## ğŸ”§ ê¸°ìˆ  ìŠ¤í™

### API ì„¤ì •
- **Model**: gpt-4o-mini
- **Temperature**: 0.9
- **Max tokens**: 800
- **Timeout**: 60ì´ˆ
- **Retries**: 1íšŒ
- **Rate limit**: 500 RPM

### ë³‘ë ¬ ì‹¤í–‰ ì „ëµ
- ìµœëŒ€ ë™ì‹œ ì‹¤í–‰: 3ê°œ í”„ë¡œì„¸ìŠ¤
- ì´ìœ : API rate limit ë°©ì§€
- ê° í”„ë¡œì„¸ìŠ¤ëŠ” ë…ë¦½ëœ í„°ë¯¸ë„ì—ì„œ background ì‹¤í–‰

---

## ğŸ“ êµí›ˆ ë° ê°œì„ ì‚¬í•­

### ë¬¸ì œì  ë° í•´ê²°

1. **API Rate Limiting**
   - ë¬¸ì œ: 6ê°œ ë³‘ë ¬ â†’ 500 RPM ì´ˆê³¼
   - í•´ê²°: 3ê°œì”© ìˆœì°¨ ë°°ì¹˜

2. **í„°ë¯¸ë„ ê´€ë¦¬**
   - ë¬¸ì œ: ì‹¤í–‰ ì¤‘ì¸ í„°ë¯¸ë„ì—ì„œ ëª…ë ¹ ì‹¤í–‰ â†’ í”„ë¡œì„¸ìŠ¤ ì¤‘ë‹¨
   - í•´ê²°: í•­ìƒ ìƒˆ í„°ë¯¸ë„ ì‚¬ìš©, isBackground=true

3. **ì„¸ì…˜ ì¤‘ë³µ**
   - ë¬¸ì œ: ê° ë¼ë²¨ì´ ë…ë¦½ì ìœ¼ë¡œ ìƒ˜í”Œë§ â†’ ì¤‘ë³µ ë°œìƒ
   - í•´ê²°: ì‚¬ì „ì— ì„¸ì…˜ í• ë‹¹ í›„ ê° ë¼ë²¨ì— ê³ ìœ  prefix íŒŒì¼ ì œê³µ

4. **ë³µêµ¬ ì „ëµ**
   - ë¬¸ì œ: ë¶€ë¶„ ì‹¤íŒ¨ ì‹œ ì²˜ìŒë¶€í„° ì¬ìƒì„±
   - í•´ê²°: Part ë¶„í•  + ë³‘í•© ì „ëµ

### Best Practices

âœ… **í•  ê²ƒ**:
- ì„¸ì…˜ í• ë‹¹ì„ ì‚¬ì „ì— ëª…í™•íˆ ë¶„ë¦¬
- ë³‘ë ¬ ì‹¤í–‰ì€ API limit ê³ ë ¤ (3-4ê°œ ê¶Œì¥)
- Progress ë¡œê·¸ ìì£¼ ì¶œë ¥ (20ê°œë§ˆë‹¤)
- ê° PartëŠ” ë…ë¦½ì ìœ¼ë¡œ ì €ì¥
- ìµœì¢… ë³‘í•© ì „ì— ê²€ì¦

âŒ **í•˜ì§€ ë§ ê²ƒ**:
- ì‹¤í–‰ ì¤‘ì¸ í„°ë¯¸ë„ì—ì„œ ìƒˆ ëª…ë ¹ ì‹¤í–‰
- 6ê°œ ì´ìƒ ë³‘ë ¬ í”„ë¡œì„¸ìŠ¤
- ê°™ì€ poolì—ì„œ ê° ë¼ë²¨ì´ ë…ë¦½ ìƒ˜í”Œë§
- ë¶€ë¶„ ì‹¤íŒ¨ ì‹œ ì „ì²´ ì¬ìƒì„±

---

## ğŸ“‚ íŒŒì¼ êµ¬ì¡°

### ì…ë ¥ íŒŒì¼
```
ESConv_normal_prefixes.json       # 1225 ì¼ë°˜ ì„¸ì…˜
ESConv_v5_prefixes.json           # 75 ìœ„ê¸° ì„¸ì…˜
```

### í• ë‹¹ íŒŒì¼ (Phase 7.2 ìƒì„±)
```
ESConv_v1_assigned.json           # 200 sessions for V1
ESConv_v2_assigned.json           # 200 sessions for V2
ESConv_v3_assigned.json           # 200 sessions for V3
ESConv_v4_assigned.json           # 100 sessions for V4
ESConv_normal_assigned.json       # 525 sessions for Normal
ESConv_v5_assigned.json           # 75 sessions for V5
session_assignments.json          # Assignment record
```

### ìƒì„± ìŠ¤í¬ë¦½íŠ¸
```
gen_v1.py                         # V1 generator
gen_v2.py                         # V2 generator
gen_v3.py                         # V3 generator
gen_v4.py                         # V4 generator
gen_normal_part1.py               # Normal part 1 (0-175)
gen_normal_part2.py               # Normal part 2 (175-350)
gen_normal_part3.py               # Normal part 3 (350-525)
```

### ì¶œë ¥ íŒŒì¼ (ì˜ˆì •)
```
generated_V1.json                 # 200 samples
generated_V2.json                 # 200 samples
generated_V3.json                 # 200 samples
generated_V4.json                 # 100 samples
generated_Normal_part1.json       # 175 samples
generated_Normal_part2.json       # 175 samples
generated_Normal_part3.json       # 175 samples
generated_Normal.json             # 525 samples (merged)
```

### ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ (ì‘ì„± ì˜ˆì •)
```
merge_final_normal.py             # Normal parts merger
verify_final_dataset.py           # Final validation
split_train_test.py               # Train/Test split
```

---

## ğŸ“ ìš”ì•½

**í˜„ì¬ ìœ„ì¹˜**: Phase 7.3 ì™„ë£Œ, Phase 8 ëŒ€ê¸° ì¤‘

**ì¤€ë¹„ ì™„ë£Œ**:
- âœ… 1300ê°œ ìœ ë‹ˆí¬ ì„¸ì…˜ í• ë‹¹
- âœ… 7ê°œ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„
- âœ… ì¤‘ë³µ ì—†ìŒ ê²€ì¦ ì™„ë£Œ

**ë‹¤ìŒ ì•¡ì…˜**:
1. 1ì°¨ ë°°ì¹˜ ì‹¤í–‰ (V1, V2, V3)
2. 2ì°¨ ë°°ì¹˜ ì‹¤í–‰ (V4, Normal_part1, Normal_part2)
3. 3ì°¨ ë°°ì¹˜ ì‹¤í–‰ (Normal_part3)
4. Normal ë³‘í•©
5. ìµœì¢… ê²€ì¦
6. Train/Test ë¶„í• 

**ì˜ˆìƒ ì™„ë£Œ**: 2-3ì‹œê°„ ë‚´

---

**ì‘ì„±ì**: GitHub Copilot  
**ê²€í† **: í•„ìš” ì‹œ ì—…ë°ì´íŠ¸
