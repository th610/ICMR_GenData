"""
ESConv ì›ë³¸ ë°ì´í„°ì—ì„œ ìœˆë„ìš° ì¶”ì¶œ í›„ Judge í‰ê°€
ì „ì²´ ëŒ€í™”ê°€ ì•„ë‹Œ 13~20í„´ ëœë¤ êµ¬ê°„ì„ ì¶”ì¶œí•˜ì—¬ í‰ê°€
ë§ˆì§€ë§‰ ë°œí™”ëŠ” ë°˜ë“œì‹œ supporterì—¬ì•¼ í•¨
"""

import json
import random
from pathlib import Path
import sys
from collections import Counter

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.llm.openai_client import OpenAIClient
from src.llm.prompts import JUDGE_SYSTEM, build_judge_prompt


def extract_window(dialog: list, min_turns: int = 13, max_turns: int = 20):
    """ëŒ€í™” ì²˜ìŒë¶€í„° 13~20í„´ ì¶”ì¶œ, ë§ˆì§€ë§‰ì€ ë°˜ë“œì‹œ supporter"""
    
    total_turns = len(dialog)
    
    # ìµœì†Œ í„´ ìˆ˜ í™•ì¸
    if total_turns < min_turns:
        return None
    
    # ëª©í‘œ ìœˆë„ìš° í¬ê¸° ê²°ì • (13~20 ì‚¬ì´)
    target_window_size = random.randint(min_turns, min(max_turns, total_turns))
    
    # ì²˜ìŒë¶€í„° target_window_sizeë§Œí¼ ìë¥´ê¸°
    window = dialog[:target_window_size]
    
    # ë§ˆì§€ë§‰ì´ supporterì¸ì§€ í™•ì¸
    if window and window[-1].get('speaker') == 'supporter':
        return window
    
    # supporterê°€ ì•„ë‹ˆë©´ ì•ì—ì„œë¶€í„° supporter ì°¾ê¸°
    for i in range(min_turns - 1, min(max_turns, total_turns)):
        if dialog[i].get('speaker') == 'supporter':
            return dialog[:i+1]
    
    return None


def load_and_extract_esconv(filepath: Path, num_samples: int = 20):
    """ESConv.jsonì—ì„œ ëœë¤ ìƒ˜í”Œë§ í›„ ìœˆë„ìš° ì¶”ì¶œ"""
    
    print(f"ğŸ“‚ {filepath.name} ë¡œë“œ ì¤‘...")
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"   ì´ ì„¸ì…˜: {len(data)}ê°œ")
    
    # ëœë¤ ìƒ˜í”Œë§
    random.seed(42)  # ì¬í˜„ì„±
    sampled = random.sample(data, min(num_samples, len(data)))
    
    # ìœˆë„ìš° ì¶”ì¶œ
    windowed_sessions = []
    failed_count = 0
    
    for i, session in enumerate(sampled):
        dialog = session.get('dialog', [])
        
        # ìœˆë„ìš° ì¶”ì¶œ
        window = extract_window(dialog, min_turns=13, max_turns=20)
        
        if window:
            windowed_session = {
                'session_id': f"esconv_window_{i:04d}",
                'situation': session.get('situation', ''),
                'dialog': window,
                'original_turns': len(dialog),
                'window_turns': len(window)
            }
            windowed_sessions.append(windowed_session)
        else:
            failed_count += 1
    
    print(f"   âœ… ìœˆë„ìš° ì¶”ì¶œ ì„±ê³µ: {len(windowed_sessions)}ê°œ")
    print(f"   âŒ ìœˆë„ìš° ì¶”ì¶œ ì‹¤íŒ¨: {failed_count}ê°œ (ëŒ€í™” ë„ˆë¬´ ì§§ê±°ë‚˜ supporter ì—†ìŒ)")
    
    return windowed_sessions


def judge_session(session: dict, llm_client: OpenAIClient):
    """ê°œë³„ ì„¸ì…˜ Judge í‰ê°€"""
    
    session_id = session.get('session_id', 'unknown')
    
    try:
        # ëŒ€í™” êµ¬ì„±
        situation = session.get('situation', '')
        dialog = session.get('dialog', [])
        
        dialog_lines = [f"[ìƒí™©]\n{situation}\n"]
        dialog_lines.append("[ëŒ€í™”]")
        
        for i, turn in enumerate(dialog):
            speaker = turn.get('speaker', 'unknown')
            content = turn.get('content', '')
            marker = " â† í‰ê°€ ëŒ€ìƒ" if i == len(dialog) - 1 else ""
            dialog_lines.append(f"[{speaker.upper()}] {content}{marker}")
        
        full_dialog_text = "\n".join(dialog_lines)
        
        # Judge í”„ë¡¬í”„íŠ¸
        user_prompt = build_judge_prompt(full_dialog=full_dialog_text)
        
        # LLM í˜¸ì¶œ
        response = llm_client.call(
            system_prompt=JUDGE_SYSTEM,
            user_prompt=user_prompt
        )
        
        result = {
            'session_id': session_id,
            'predicted_label': response.get('label', 'Unknown'),
            'reason': response.get('reason', ''),
            'confidence': response.get('confidence', 'unknown'),
            'situation': situation,
            'dialog': dialog,
            'window_turns': session.get('window_turns', len(dialog)),
            'original_turns': session.get('original_turns', len(dialog))
        }
        
        return result
        
    except Exception as e:
        print(f"  âŒ Error: {e}")
        return {
            'session_id': session_id,
            'predicted_label': 'Error',
            'reason': str(e),
            'confidence': 'error'
        }


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    print("=" * 80)
    print("ESConv ì›ë³¸ ë°ì´í„° Judge í‰ê°€ (ìœˆë„ìš° ë°©ì‹)")
    print("ë°©ì‹: ì²˜ìŒë¶€í„° 13~20í„´ ì¶”ì¶œ, ë§ˆì§€ë§‰ì€ supporter")
    print("=" * 80)
    print()
    
    # ESConv íŒŒì¼ ê²½ë¡œ
    esconv_path = Path(__file__).parent.parent.parent / "ESConv.json"
    output_path = Path(__file__).parent.parent.parent / "data" / "pilot" / "judge_esconv_window_20.json"
    
    if not esconv_path.exists():
        print(f"âŒ ESConv.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {esconv_path}")
        return
    
    # ìœˆë„ìš° ì¶”ì¶œ
    sessions = load_and_extract_esconv(esconv_path, num_samples=20)
    
    if not sessions:
        print("âŒ ìœˆë„ìš° ì¶”ì¶œëœ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ² í‰ê°€ ëŒ€ìƒ: {len(sessions)}ê°œ")
    print()
    
    # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    print("ğŸ”§ LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”...")
    llm_client = OpenAIClient(
        model="gpt-4o-mini",
        temperature=0.3,
        max_tokens=300
    )
    print()
    
    # Judge í‰ê°€
    print("ğŸ” Judge í‰ê°€ ì‹œì‘...")
    print("=" * 80)
    
    results = []
    
    for i, session in enumerate(sessions, 1):
        session_id = session.get('session_id', 'unknown')
        window_turns = session.get('window_turns', 0)
        original_turns = session.get('original_turns', 0)
        
        print(f"\n[{i}/{len(sessions)}] {session_id} ({window_turns}/{original_turns}í„´)...", end=" ", flush=True)
        
        result = judge_session(session, llm_client)
        results.append(result)
        
        # ê°„ë‹¨í•œ ì¶œë ¥
        predicted = result.get('predicted_label', 'Unknown')
        confidence = result.get('confidence', 'unknown')
        
        print(f"{predicted} ({confidence})")
        if predicted != 'Normal':
            reason = result.get('reason', 'N/A')[:60]
            print(f"      ì´ìœ : {reason}...")
    
    # í†µê³„ ì¶œë ¥
    print("\n" + "=" * 80)
    print("í‰ê°€ ê²°ê³¼ í†µê³„")
    print("=" * 80)
    
    label_counts = Counter([r['predicted_label'] for r in results])
    
    print(f"\n{'ë ˆì´ë¸”':<15} {'ê°œìˆ˜':<8} {'ë¹„ìœ¨':<10}")
    print("â”€" * 40)
    
    for label in ['Normal', 'V1', 'V2', 'V3', 'V4', 'V5', 'Error']:
        count = label_counts.get(label, 0)
        ratio = (count / len(results) * 100) if len(results) > 0 else 0
        if count > 0:
            print(f"{label:<15} {count:<8} {ratio:<10.1f}%")
    
    print("â”€" * 40)
    print(f"{'TOTAL':<15} {len(results):<8} {'100.0%':<10}")
    
    # ìœ„ë°˜ ë¹„ìœ¨
    violation_count = sum(label_counts[label] for label in ['V1', 'V2', 'V3', 'V4', 'V5'])
    violation_ratio = (violation_count / len(results) * 100) if len(results) > 0 else 0
    
    print(f"\nğŸ“Š Normal: {label_counts.get('Normal', 0)}ê°œ ({100-violation_ratio:.1f}%)")
    print(f"ğŸ“Š ìœ„ë°˜ ìˆìŒ: {violation_count}ê°œ ({violation_ratio:.1f}%)")
    
    # ê²°ê³¼ ì €ì¥
    output_data = {
        'total': len(results),
        'statistics': dict(label_counts),
        'violation_ratio': violation_ratio,
        'window_config': {
            'min_turns': 13,
            'max_turns': 20,
            'last_speaker': 'supporter'
        },
        'results': results
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
    
    print("\n" + "=" * 80)
    print("âœ… ESConv ìœˆë„ìš° Judge ì™„ë£Œ!")
    print("=" * 80)


if __name__ == "__main__":
    main()
