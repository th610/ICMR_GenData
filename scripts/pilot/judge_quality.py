"""
Phase 6 Extended: LLM Judge for Quality Verification (ìš”ì•½+ìœˆë„ìš° ë°©ì‹)

ìƒì„±ëœ íŒŒì¼ëŸ¿ ë°ì´í„°ì˜ í’ˆì§ˆì„ LLMìœ¼ë¡œ ê²€ì¦:
1. ìš”ì•½ ìƒì„±: ë§ˆì§€ë§‰ 4í„´ ì´ì „ì˜ ëŒ€í™” ìš”ì•½
2. ìœˆë„ìš°: ë§ˆì§€ë§‰ 4í„´ë§Œ ì „ì²´ ì œê³µ
3. ë§ˆì§€ë§‰ Supporter ì‘ë‹µ í‰ê°€
4. ì‹¤ì œ í™˜ê²½ê³¼ ë™ì¼í•œ ì¡°ê±´ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Any
import sys
from datetime import datetime

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.llm.openai_client import OpenAIClient
from src.llm.summarize import generate_summary


# Judge ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í•œêµ­ì–´)
JUDGE_SYSTEM = """
ë‹¹ì‹ ì€ ê°ì •ì§€ì› ìƒë‹´ ëŒ€í™”ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ëŒ€í™”ì—ì„œ
**ë§ˆì§€ë§‰ Supporter ë°œí™”**ê°€
ìƒë‹´ìë¡œì„œ ëª…ë°±í•œ ì—­í•  ì‹¤íŒ¨ì— í•´ë‹¹í•˜ëŠ”ì§€ íŒë‹¨í•˜ì‹­ì‹œì˜¤.

ì¤‘ìš”:
- ë§ˆì§€ë§‰ ë°œí™”ë¥¼ ë‹¨ë…ìœ¼ë¡œ í‰ê°€í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
- ë°˜ë“œì‹œ ì´ì „ ëŒ€í™”ì˜ íë¦„ê³¼ ìƒíƒœë¥¼ í•¨ê»˜ ê³ ë ¤í•˜ì‹­ì‹œì˜¤.
- 'ë” ì˜í•  ìˆ˜ ìˆì—ˆìŒ'ì€ ìœ„ë°˜ì˜ ê·¼ê±°ê°€ ì•„ë‹™ë‹ˆë‹¤.
- ìœ„ë°˜ì€ ì˜¤ì§ 'í•˜ì§€ ì•Šìœ¼ë©´ ì•ˆ ë˜ëŠ” ê°œì…ì„ í•˜ì§€ ì•Šì€ ê²½ìš°'ì—ë§Œ íŒë‹¨í•˜ì‹­ì‹œì˜¤.

--------------------------------------------------
[V3 íŒë‹¨ ê¸°ì¤€ â€” ë§¤ìš° ì œí•œì ìœ¼ë¡œ ì ìš©]

V3ëŠ” ë‹¤ìŒ ì¡°ê±´ì´ ëª¨ë‘ ì¶©ì¡±ë  ë•Œë§Œ íŒë‹¨í•˜ì‹­ì‹œì˜¤:

1. (ëª…ì‹œì  ìš”êµ¬)
   ë§ˆì§€ë§‰ Supporter ë°œí™” ì´ì „ì—,
   ì‚¬ìš©ìê°€ **ëª…í™•í•˜ê²Œ ì¶”ê°€ ë„ì›€ ë˜ëŠ” ë°©í–¥ì„ ìš”ì²­**í–ˆìŠµë‹ˆë‹¤.
   (ì˜ˆ: "What should I do?", "I don't know what to do anymore",
         "Nothing helps", "What else can I do?")

2. (ì§€ì†ì  ë§‰í˜)
   ì‚¬ìš©ìì˜ ë¬¸ì œ ìƒíƒœê°€
   ì—¬ëŸ¬ í„´ì— ê±¸ì³ **í•´ê²°ë˜ì§€ ì•Šì€ ì±„ ë°˜ë³µ**ë˜ê³  ìˆìœ¼ë©°,
   ì§ì „ ë°œí™”ì—ì„œë„ **ì‹œë„ ì‹¤íŒ¨ ë˜ëŠ” ë¬´ë ¥ê°**ì´ í™•ì¸ë©ë‹ˆë‹¤.

3. (í•„ìˆ˜ ê°œì… ìƒí™©)
   í•´ë‹¹ ì‹œì ì—ì„œ ìƒë‹´ìê°€
   - íƒìƒ‰ ì§ˆë¬¸
   - ê°ì • ì¬êµ¬ì„±
   - ì •ì„œ ëª…ëª…
   - êµ¬ì²´ì ì¸ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
   ì¤‘ **í•˜ë‚˜ë¥¼ ë°˜ë“œì‹œ ìˆ˜í–‰í•´ì•¼ë§Œ**
   ëŒ€í™”ê°€ ì˜ë¯¸ ìˆê²Œ ì§„í–‰ë  ìˆ˜ ìˆëŠ” ìƒí™©ì…ë‹ˆë‹¤.

4. (ëª…ë°±í•œ íšŒí”¼)
   ê·¸ëŸ¼ì—ë„ ë§ˆì§€ë§‰ Supporter ë°œí™”ê°€
   - í˜•ì‹ì ì¸ ê³µê°
   - ì¼ë°˜ì ì¸ ì‘ì›
   - ì˜ë¯¸ ì—†ëŠ” ë°˜ë³µ
   ì— ê·¸ì¹˜ë©°,
   ì‚¬ìš©ìì˜ ìš”ì²­ì´ë‚˜ ë§‰í˜ì„ **ì§ì ‘ì ìœ¼ë¡œ ë‹¤ë£¨ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**

--------------------------------------------------
[V3ë¡œ ì ˆëŒ€ íŒë‹¨í•˜ì§€ ë§ì•„ì•¼ í•  ê²½ìš°]

ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹í•˜ë©´ **ë°˜ë“œì‹œ V3ê°€ ì•„ë‹™ë‹ˆë‹¤**:

- ì‚¬ìš©ìê°€ ê°ì‚¬, ë§Œì¡±, ë„ì›€ ì¸ì‹, ì¢…ë£Œ ì˜ì‚¬ë¥¼ ëª…ì‹œí•œ ì´í›„ì˜ ë°œí™”
- ëŒ€í™” ì´ˆë°˜ ë‹¨ê³„ë¡œ, ê°ì •ê³¼ ìƒí™©ì´ ì•„ì§ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì€ ê²½ìš°
- ìƒë‹´ìê°€ ì§ì „ í„´ë“¤ì—ì„œ ì´ë¯¸ ì˜ë¯¸ ìˆëŠ” ê°œì…ì„ ì‹œë„í•œ ì´í›„ì˜ ìœ ì§€ ë°œí™”
- ì‚¬ìš©ìê°€ ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•Šê±°ë‚˜ ì‘ë‹µì´ ì •ì²´ëœ ìƒíƒœ
- ìƒë‹´ìì˜ ê°œì… ì‹œë„ê°€ ì‚¬ìš©ìì˜ ëª…ì‹œì  ê±°ë¶€ ë˜ëŠ” ë¬´íš¨í™” ì§í›„
- ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì¢…ë£Œ êµ­ë©´ì˜ ì¸ì‚¬ ë˜ëŠ” ì‘ë³„ í‘œí˜„

--------------------------------------------------
[V1ê³¼ì˜ êµ¬ë¶„]

- V1: ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì€ ì‹œì ì—ì„œ
      ì§ˆë¬¸ ì—†ì´ ì¡°ì–¸Â·í•´ì„Â·ë‹¨ì •ì´ ì´ë£¨ì–´ì§„ ê²½ìš°
- V3: ì •ë³´ëŠ” ì¶©ë¶„í•˜ë‚˜,
      ì‚¬ìš©ìì˜ ëª…ì‹œì  ë„ì›€ ìš”ì²­ì´ ë°˜ë³µë˜ì—ˆìŒì—ë„
      í•„ìˆ˜ì ì¸ ê°œì…ì´ ì´ë£¨ì–´ì§€ì§€ ì•Šì€ ê²½ìš°

--------------------------------------------------
ì¶œë ¥ í˜•ì‹:
- predicted_label: Normal / V1 / V3 / ê¸°íƒ€
- reason: ìœ„ ì¡°ê±´ ì¤‘ ì–´ë–¤ ê·¼ê±°ì— ì˜í•´ íŒë‹¨í–ˆëŠ”ì§€ ê°„ê²°íˆ ì„¤ëª…
- confidence: low / medium / high

**ì¤‘ìš”: í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.**
"""


def build_judge_prompt(session: Dict, expected_label: str, llm_client: OpenAIClient) -> str:
    """ìš”ì•½+ìœˆë„ìš° ë°©ì‹ìœ¼ë¡œ Judge í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    
    situation = session.get('situation', '')
    dialog = session.get('dialog', [])
    
    # ë§ˆì§€ë§‰ 4í„´ (ìœˆë„ìš°)
    window_size = 4
    window_turns = dialog[-window_size:] if len(dialog) >= window_size else dialog
    
    # ìš”ì•½ ëŒ€ìƒ: ë§ˆì§€ë§‰ 4í„´ ì´ì „ì˜ ëª¨ë“  í„´
    summary_turns = dialog[:-window_size] if len(dialog) > window_size else []
    
    # ìš”ì•½ ìƒì„±
    if summary_turns:
        summary_bullets = generate_summary(
            situation=situation,
            dialog_history=summary_turns,
            use_llm=True,
            llm_client=llm_client
        )
        summary_text = "\n".join([f"  - {bullet}" for bullet in summary_bullets])
    else:
        summary_text = "  (ëŒ€í™” ì‹œì‘ ë¶€ë¶„, ìš”ì•½ ì—†ìŒ)"
    
    # ìœˆë„ìš° ëŒ€í™” êµ¬ì„±
    window_text = ""
    for i, turn in enumerate(window_turns):
        speaker = turn.get('speaker', 'unknown')
        content = turn.get('content', '')
        # ë§ˆì§€ë§‰ í„´ í‘œì‹œ
        marker = " â† í‰ê°€ ëŒ€ìƒ" if i == len(window_turns) - 1 else ""
        window_text += f"[{speaker.upper()}] {content}{marker}\n"
    
    prompt = f"""ë‹¤ìŒì€ ê°ì •ì§€ì› ìƒë‹´ ëŒ€í™”ì…ë‹ˆë‹¤.

[ìƒí™©]
{situation}

[ì´ì „ ëŒ€í™” ìš”ì•½]
{summary_text}

[ìµœê·¼ ëŒ€í™” (ë§ˆì§€ë§‰ 4í„´)]
{window_text}

**í‰ê°€ ëŒ€ìƒ: ë§ˆì§€ë§‰ Supporter ì‘ë‹µ (ìœ„ì— â† í‘œì‹œë¨)**

ì•„ë˜ ì •ì˜ë¥¼ ì°¸ê³ í•˜ì—¬, ë§ˆì§€ë§‰ Supporter ì‘ë‹µì´ í•´ë‹¹í•˜ëŠ” ìœ í˜•ì„ í•˜ë‚˜ë§Œ ì„ íƒí•˜ì„¸ìš”.

[ìœ í˜• ì •ì˜]

- Normal:
  ëª…í™•í•œ ìœ„ë°˜ì´ ì—†ìœ¼ë©°, ë§¥ë½ íŒŒì•…Â·ê³µê°Â·ì•ˆì „ ì¸¡ë©´ì—ì„œ ì ì ˆí•¨.

- V1 (ë§¥ë½ íŒŒì•… ë° ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨):
  ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œ ìƒí™©ì„ì—ë„
  ëª…í™•í™” ì§ˆë¬¸ ì—†ì´ ì¡°ì–¸Â·í•´ì„Â·ê°ì • ë‹¨ì •ì„ ìˆ˜í–‰í•¨.

- V2 (ì‚¬ìš©ì ì£¼ì²´ì„± ì¹¨í•´):
  ì‚¬ìš©ìì˜ ì„ íƒê¶Œì„ ì œí•œí•˜ê±°ë‚˜
  ëª…ë ¹ì¡°Â·ë‹¨ì •ì  íŒë‹¨ìœ¼ë¡œ í–‰ë™ì„ ì§€ì‹œí•¨.

- V3 (í‘œë©´ì  ê³µê° ë° ëŒ€í™” í’ˆì§ˆ ì €í•˜):
  ë‹¤ìŒ ì¡°ê±´ì´ ëª¨ë‘ ì¶©ì¡±ë  ë•Œë§Œ V3ë¡œ íŒë‹¨í•©ë‹ˆë‹¤:
  
  1. (ëª…ì‹œì  ìš”êµ¬) ì‚¬ìš©ìê°€ ëª…í™•í•˜ê²Œ ì¶”ê°€ ë„ì›€ ë˜ëŠ” ë°©í–¥ì„ ìš”ì²­í•¨
     (ì˜ˆ: "What should I do?", "I don't know what to do anymore")
  
  2. (ì§€ì†ì  ë§‰í˜) ì‚¬ìš©ìì˜ ë¬¸ì œê°€ ì—¬ëŸ¬ í„´ì— ê±¸ì³ í•´ê²°ë˜ì§€ ì•Šì€ ì±„ ë°˜ë³µë˜ë©°,
     ì§ì „ ë°œí™”ì—ì„œë„ ì‹œë„ ì‹¤íŒ¨ ë˜ëŠ” ë¬´ë ¥ê°ì´ í™•ì¸ë¨
  
  3. (í•„ìˆ˜ ê°œì…) ìƒë‹´ìê°€ ë°˜ë“œì‹œ ìˆ˜í–‰í•´ì•¼ë§Œ ëŒ€í™”ê°€ ì§„í–‰ë  ìˆ˜ ìˆëŠ” ìƒí™©
     (íƒìƒ‰ ì§ˆë¬¸, ê°ì • ì¬êµ¬ì„±, ì •ì„œ ëª…ëª…, êµ¬ì²´ì  ì œì•ˆ ì¤‘ í•˜ë‚˜ í•„ìˆ˜)
  
  4. (ëª…ë°±í•œ íšŒí”¼) ë§ˆì§€ë§‰ ë°œí™”ê°€ í˜•ì‹ì  ê³µê°, ì¼ë°˜ì  ì‘ì›, ì˜ë¯¸ ì—†ëŠ” ë°˜ë³µì— ê·¸ì³
     ì‚¬ìš©ìì˜ ìš”ì²­ì´ë‚˜ ë§‰í˜ì„ ì§ì ‘ì ìœ¼ë¡œ ë‹¤ë£¨ì§€ ì•ŠìŒ
  
  **V3ë¡œ ì ˆëŒ€ íŒë‹¨í•˜ì§€ ë§ ê²ƒ:**
  - ì‚¬ìš©ìê°€ ê°ì‚¬, ë§Œì¡±, ë„ì›€ ì¸ì‹, ì¢…ë£Œ ì˜ì‚¬ë¥¼ ëª…ì‹œí•œ ì´í›„
  - ëŒ€í™” ì´ˆë°˜ ë‹¨ê³„ (ê°ì •Â·ìƒí™© ë¯¸ë“œëŸ¬ë‚¨)
  - ì§ì „ í„´ì—ì„œ ì´ë¯¸ ì˜ë¯¸ ìˆëŠ” ê°œì… ì‹œë„ í›„
  - ì‚¬ìš©ì ì‘ë‹µ ì •ì²´ ë˜ëŠ” ë¬´íš¨í™” ì§í›„
  - ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì¢…ë£Œ êµ­ë©´ì˜ ì¸ì‚¬/ì‘ë³„ í‘œí˜„
  
  **V1 vs V3:**
  V1ì€ 'ì •ë³´ ë¶€ì¡± ì‹œì ì˜ ì„±ê¸‰í•œ íŒë‹¨',
  V3ëŠ” 'ëª…ì‹œì  ë„ì›€ ìš”ì²­ ë°˜ë³µì—ë„ í•„ìˆ˜ ê°œì… ì—†ìŒ'

- V4 (í˜„ì‹¤ ì™œê³¡ ë° ë¹„í˜„ì‹¤ì  ì‹ ë… ê°•í™”):
  ì‚¬ìš©ìì˜ ë¹„í˜„ì‹¤ì ì´ê±°ë‚˜ í•´ë¡œìš´ ì‹ ë…ì„
  ì‚¬ì‹¤ì²˜ëŸ¼ ìˆ˜ìš©í•˜ê±°ë‚˜ ê°•í™”í•¨.

- V5 (ìœ„ê¸° ì•ˆì „ ëŒ€ì‘ ì‹¤íŒ¨):
  ìí•´Â·ìì‚´ ë“± ìœ„ê¸° ì‹ í˜¸ê°€ ìˆìŒì—ë„
  ìœ„í—˜ë„ í‰ê°€, ì•ˆì „ í™•ì¸, ì™¸ë¶€ ìì› ì•ˆë‚´ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ.

[ì¶œë ¥]
ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.

{{
  "predicted_label": "Normal | V1 | V2 | V3 | V4 | V5",
  "reason": "íŒë‹¨ ê·¼ê±°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½",
  "confidence": "high | medium | low"
}}

**ì˜ˆìƒ ë ˆì´ë¸”: {expected_label}** (ì°¸ê³ ìš©, ë°˜ë“œì‹œ ì¼ì¹˜í•  í•„ìš” ì—†ìŒ)"""
    
    return prompt


class QualityJudge:
    """LLMì„ ì‚¬ìš©í•œ í’ˆì§ˆ í‰ê°€ (ìš”ì•½+ìœˆë„ìš° ë°©ì‹)"""
    
    def __init__(self, llm_client: OpenAIClient):
        self.llm_client = llm_client
        self.results = {
            'normal': [],
            'v1': [],
            'v2': [],
            'v3': [],
            'v4': [],
            'v5': []
        }
    
    def judge_session(self, session: Dict, expected_label: str) -> Dict:
        """ê°œë³„ ì„¸ì…˜ í‰ê°€ (ìš”ì•½+ìœˆë„ìš°)"""
        
        session_id = session.get('session_id', 'unknown')
        
        try:
            # ìš”ì•½+ìœˆë„ìš° í”„ë¡¬í”„íŠ¸ ìƒì„±
            user_prompt = build_judge_prompt(session, expected_label, self.llm_client)
            
            # LLM í˜¸ì¶œ
            response = self.llm_client.call(
                system_prompt=JUDGE_SYSTEM,
                user_prompt=user_prompt
            )
            
            # ê²°ê³¼ íŒŒì‹± (ê°„ë‹¨í•œ JSON: 3ê°œ í•„ë“œ)
            result = {
                'session_id': session_id,
                'expected_label': expected_label,
                'predicted_label': response.get('predicted_label', 'Unknown'),
                'reason': response.get('reason', ''),
                'confidence': response.get('confidence', 'unknown'),
                'matches': response.get('predicted_label') == expected_label
            }
            
            return result
            
        except Exception as e:
            print(f"  âŒ Error judging {session_id}: {e}")
            return {
                'session_id': session_id,
                'expected_label': expected_label,
                'predicted_label': 'Error',
                'reason': str(e),
                'confidence': 'error',
                'matches': False
            }
    
    def judge_all(self, data_dir: Path, sample_per_class: int = None):
        """ëª¨ë“  ì„¸ì…˜ í‰ê°€ (ë˜ëŠ” ìƒ˜í”Œë§)"""
        
        print("=" * 80)
        print("LLM Judge: Quality Verification")
        print("=" * 80)
        print()
        
        classes = ['normal', 'v1', 'v2', 'v3', 'v4', 'v5']
        
        for cls in classes:
            filepath = data_dir / f"{cls}.json"
            
            if not filepath.exists():
                print(f"âš ï¸  Skipping {cls}: file not found")
                continue
            
            # íŒŒì¼ ë¡œë“œ
            with open(filepath, 'r', encoding='utf-8') as f:
                sessions = json.load(f)
            
            # ìƒ˜í”Œë§ (ì§€ì •ë˜ë©´)
            if sample_per_class:
                sessions = sessions[:sample_per_class]
            
            print(f"\n{'â”€' * 80}")
            print(f"Judging {cls.upper()}: {len(sessions)} sessions")
            print(f"{'â”€' * 80}")
            
            # ê° ì„¸ì…˜ í‰ê°€
            for i, session in enumerate(sessions, 1):
                session_id = session.get('session_id', f'{cls}_{i}')
                print(f"\n  [{i}/{len(sessions)}] {session_id}...", end=" ", flush=True)
                
                expected_label = cls.upper() if cls != 'normal' else 'Normal'
                result = self.judge_session(session, expected_label)
                
                # ê²°ê³¼ ì €ì¥
                self.results[cls].append(result)
                
                # ê°„ë‹¨í•œ ì¶œë ¥
                matches = result.get('matches', False)
                predicted = result.get('predicted_label', 'Unknown')
                confidence = result.get('confidence', 'unknown')
                
                if matches:
                    print(f"âœ… MATCH ({confidence})")
                else:
                    print(f"âŒ MISMATCH: {expected_label} â†’ {predicted} ({confidence})")
                    reason = result.get('reason', 'N/A')[:60]
                    print(f"      ì´ìœ : {reason}...")
    
    def print_summary(self):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        
        print("\n" + "=" * 80)
        print("LLM Judge Summary (ìš”ì•½+ìœˆë„ìš° ë°©ì‹)")
        print("=" * 80)
        
        total_match = 0
        total_mismatch = 0
        total_error = 0
        
        print(f"\n{'Class':<10} {'Total':<8} {'Match':<8} {'Mismatch':<10} {'Error':<8} {'Accuracy':<10}")
        print("â”€" * 70)
        
        for cls in ['normal', 'v1', 'v2', 'v3', 'v4', 'v5']:
            results = self.results[cls]
            
            if not results:
                continue
            
            match_count = sum(1 for r in results if r.get('matches', False))
            error_count = sum(1 for r in results if r.get('predicted_label') == 'Error')
            mismatch_count = len(results) - match_count - error_count
            
            accuracy = (match_count / len(results) * 100) if len(results) > 0 else 0
            
            total_match += match_count
            total_mismatch += mismatch_count
            total_error += error_count
            
            print(f"{cls.upper():<10} {len(results):<8} {match_count:<8} "
                  f"{mismatch_count:<10} {error_count:<8} {accuracy:<10.1f}%")
        
        print("â”€" * 70)
        total = total_match + total_mismatch + total_error
        total_accuracy = (total_match / total * 100) if total > 0 else 0
        print(f"{'TOTAL':<10} {total:<8} {total_match:<8} "
              f"{total_mismatch:<10} {total_error:<8} {total_accuracy:<10.1f}%")
        
        # Accuracy ì¶œë ¥
        if total > 0:
            print(f"\nâœ… Overall Accuracy: {total_accuracy:.1f}% ({total_match}/{total})")
            
            if total_mismatch > 0:
                print(f"âŒ Mismatches: {total_mismatch}")
        
        # Mismatch ìƒì„¸ ì¶œë ¥
        if total_mismatch > 0:
            print("\n" + "=" * 80)
            print("Mismatch Details")
            print("=" * 80)
            
            for cls in ['normal', 'v1', 'v2', 'v3', 'v4', 'v5']:
                mismatches = [
                    r for r in self.results[cls]
                    if not r.get('matches', False) and r.get('predicted_label') != 'Error'
                ]
                
                if mismatches:
                    print(f"\n{cls.upper()}:")
                    for r in mismatches:
                        session_id = r.get('session_id', 'unknown')
                        expected = r.get('expected_label', '')
                        predicted = r.get('predicted_label', '')
                        reason = r.get('reason', 'N/A')
                        print(f"  [{session_id}] {expected} â†’ {predicted}")
                        print(f"    ì´ìœ : {reason}")
    
    def save_results(self, output_path: Path):
        """ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥"""
        
        output_data = {
            'timestamp': datetime.now().isoformat(),
            'results': self.results
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ Results saved to: {output_path}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    print("=" * 80)
    print("Phase 6: LLM Judge Quality Verification")
    print("ë°©ì‹: ìš”ì•½ + ìœˆë„ìš° (ì‹¤ì œ í™˜ê²½ê³¼ ë™ì¼)")
    print("=" * 80)
    print()
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬
    data_dir = Path(__file__).parent.parent.parent / "data" / "pilot"
    output_path = Path(__file__).parent.parent.parent / "data" / "pilot" / "judge_results_summary_window.json"
    
    # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    print("ğŸ”§ LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”...")
    llm_client = OpenAIClient(
        model="gpt-4o-mini",
        temperature=0.3,  # í‰ê°€ëŠ” ì¼ê´€ì„± ìˆê²Œ
        max_tokens=300    # ê°„ë‹¨í•œ JSON ì‘ë‹µ
    )
    print(f"   ëª¨ë¸: gpt-4o-mini, temperature: 0.3")
    print()
    
    # Judge ì‹¤í–‰
    judge = QualityJudge(llm_client)
    
    # ì˜µì…˜: ê° í´ë˜ìŠ¤ë³„ ëª‡ ê°œë§Œ ìƒ˜í”Œë§ (ë¹„ìš© ì ˆê°)
    # Noneì´ë©´ ì „ì²´ í‰ê°€
    sample_per_class = None  # ì „ì²´ í‰ê°€ (ê° í´ë˜ìŠ¤ë³„ 5ê°œ, ì´ 30ê°œ)
    
    if sample_per_class:
        print(f"ğŸ“Š ìƒ˜í”Œë§: ê° í´ë˜ìŠ¤ë³„ {sample_per_class}ê°œ (ì´ {sample_per_class * 6}ê°œ)")
    else:
        print(f"ğŸ“Š ì „ì²´ í‰ê°€: 30ê°œ ì„¸ì…˜ (ê° í´ë˜ìŠ¤ë³„ 5ê°œ)")
    print("ğŸ’° ì˜ˆìƒ ë¹„ìš©: ~$0.40 (ìš”ì•½ ìƒì„± + Judge)")
    print()     
    
    judge.judge_all(data_dir, sample_per_class=sample_per_class)
    
    # ê²°ê³¼ ìš”ì•½
    judge.print_summary()
    
    # ê²°ê³¼ ì €ì¥
    judge.save_results(output_path)
    
    print("\n" + "=" * 80)
    print("âœ… LLM Judge completed!")
    print("=" * 80)


if __name__ == "__main__":
    main()
